{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcb552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load your data\n",
    "pitch_data = pd.DataFrame(pd.read_csv('jazmine-pitch.csv'))\n",
    "words_data = pd.DataFrame(pd.read_csv('jazmine-words.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67552f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving repeated words unique labels\n",
    "def unique_word_labels(data):\n",
    "    word_count = {}\n",
    "    last_word = None\n",
    "    unique_data = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        word = row['word']\n",
    "        \n",
    "        # Check if this is a repeated word\n",
    "        if word == last_word:\n",
    "            # Use the same label as the previous occurrence if it's in a clump\n",
    "            unique_word = unique_data[-1]['word']\n",
    "        else:\n",
    "            # If it's a new occurrence or a different word\n",
    "            count = word_count.get(word, 0) + 1\n",
    "            word_count[word] = count\n",
    "\n",
    "            if count == 1:\n",
    "                unique_word = word  # First occurrence remains the same\n",
    "            else:\n",
    "                unique_word = f\"{word}-{count}\"  # Label subsequent occurrences uniquely\n",
    "\n",
    "        # Creating a new dictionary with modified word property\n",
    "        new_item = row.to_dict()\n",
    "        new_item['word'] = unique_word\n",
    "        unique_data.append(new_item)\n",
    "\n",
    "        last_word = word  # Update the last seen word\n",
    "\n",
    "    \n",
    "    return pd.DataFrame(unique_data)\n",
    "\n",
    "words_data = unique_word_labels(words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88e0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_data(word, words_data, pitch_data):\n",
    "    word_notes = words_data[words_data['word'] == word]\n",
    "    start_time = word_notes['timestamp'].min()\n",
    "    end_time = word_notes.iloc[-1]['timestamp'] + word_notes.iloc[-1]['duration']\n",
    "\n",
    "    # Adjusting the timestamps relative to the word's start\n",
    "    adjusted_word_notes = word_notes.copy()\n",
    "    adjusted_word_notes['adjusted_timestamp'] = adjusted_word_notes['timestamp'] - start_time\n",
    "\n",
    "    # Filtering and adjusting pitch data\n",
    "    filtered_pitch_data = pitch_data[(pitch_data['timestamp'] >= start_time) & (pitch_data['timestamp'] <= end_time)].copy()\n",
    "    filtered_pitch_data['adjusted_timestamp'] = filtered_pitch_data['timestamp'] - start_time\n",
    "\n",
    "    return {\n",
    "        'word': word,\n",
    "        'note_data': adjusted_word_notes,\n",
    "        'pitch_data': filtered_pitch_data\n",
    "    }\n",
    "\n",
    "def chaos_score(pitch_data1, pitch_data2):\n",
    "    # Using FastDTW for a quick approximation\n",
    "    distance, _ = fastdtw(pitch_data1, pitch_data2, dist=euclidean)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887ecf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shape 1 of 81\n",
      "Processed shape 2 of 81\n",
      "Processed shape 3 of 81\n",
      "Processed shape 4 of 81\n",
      "Processed shape 5 of 81\n",
      "Processed shape 6 of 81\n",
      "Processed shape 7 of 81\n",
      "Processed shape 8 of 81\n",
      "Processed shape 9 of 81\n",
      "Processed shape 10 of 81\n",
      "Processed shape 11 of 81\n",
      "Processed shape 12 of 81\n",
      "Processed shape 13 of 81\n",
      "Processed shape 14 of 81\n",
      "Processed shape 15 of 81\n",
      "Processed shape 16 of 81\n",
      "Processed shape 17 of 81\n",
      "Processed shape 18 of 81\n",
      "Processed shape 19 of 81\n",
      "Processed shape 20 of 81\n",
      "Processed shape 21 of 81\n",
      "Processed shape 22 of 81\n",
      "Processed shape 23 of 81\n",
      "Processed shape 24 of 81\n",
      "Processed shape 25 of 81\n",
      "Processed shape 26 of 81\n",
      "Processed shape 27 of 81\n",
      "Processed shape 28 of 81\n",
      "Processed shape 29 of 81\n",
      "Processed shape 30 of 81\n",
      "Processed shape 31 of 81\n",
      "Processed shape 32 of 81\n",
      "Processed shape 33 of 81\n",
      "Processed shape 34 of 81\n",
      "Processed shape 35 of 81\n",
      "Processed shape 36 of 81\n",
      "Processed shape 37 of 81\n",
      "Processed shape 38 of 81\n",
      "Processed shape 39 of 81\n",
      "Processed shape 40 of 81\n",
      "Processed shape 41 of 81\n",
      "Processed shape 42 of 81\n",
      "Processed shape 43 of 81\n",
      "Processed shape 44 of 81\n",
      "Processed shape 45 of 81\n",
      "Processed shape 46 of 81\n",
      "Processed shape 47 of 81\n",
      "Processed shape 48 of 81\n",
      "Processed shape 49 of 81\n",
      "Processed shape 50 of 81\n",
      "Processed shape 51 of 81\n",
      "Processed shape 52 of 81\n",
      "Processed shape 53 of 81\n",
      "Processed shape 54 of 81\n",
      "Processed shape 55 of 81\n",
      "Processed shape 56 of 81\n",
      "Processed shape 57 of 81\n",
      "Processed shape 58 of 81\n",
      "Processed shape 59 of 81\n",
      "Processed shape 60 of 81\n",
      "Processed shape 61 of 81\n",
      "Processed shape 62 of 81\n",
      "Processed shape 63 of 81\n",
      "Processed shape 64 of 81\n",
      "Processed shape 65 of 81\n",
      "Processed shape 66 of 81\n",
      "Processed shape 67 of 81\n",
      "Processed shape 68 of 81\n",
      "Processed shape 69 of 81\n",
      "Processed shape 70 of 81\n",
      "Processed shape 71 of 81\n",
      "Processed shape 72 of 81\n",
      "Processed shape 73 of 81\n",
      "Processed shape 74 of 81\n",
      "Processed shape 75 of 81\n",
      "Processed shape 76 of 81\n",
      "Processed shape 77 of 81\n",
      "Processed shape 78 of 81\n",
      "Processed shape 79 of 81\n",
      "Processed shape 80 of 81\n",
      "Processed shape 81 of 81\n",
      "Distance matrix computation complete and saved to file.\n"
     ]
    }
   ],
   "source": [
    "# Create distance matrix\n",
    "unique_words = words_data['word'].unique()\n",
    "shapes = [get_word_data(word, words_data, pitch_data) for word in unique_words]\n",
    "num_shapes = len(shapes)\n",
    "distance_matrix = []\n",
    "filename = \"distance_matrix.npy\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(filename):\n",
    "    # Load the distance matrix\n",
    "    distance_matrix = np.load(filename)\n",
    "    print(\"Loaded distance matrix from file.\")\n",
    "else:\n",
    "    num_shapes = len(shapes)\n",
    "    distance_matrix = []\n",
    "\n",
    "    for i, shape1 in enumerate(shapes):\n",
    "        row = []\n",
    "        for j, shape2 in enumerate(shapes):\n",
    "            if i == j:\n",
    "                # Skip comparing the shape with itself and set distance to 0\n",
    "                distance = 0\n",
    "            else:\n",
    "                distance = chaos_score(shape1['pitch_data'], shape2['pitch_data'])\n",
    "            row.append(distance)\n",
    "        distance_matrix.append(row)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Processed shape {i+1} of {num_shapes}\")\n",
    "\n",
    "    # Convert to numpy array for easy saving\n",
    "    distance_matrix = np.array(distance_matrix)\n",
    "\n",
    "    # Save the distance matrix to a file\n",
    "    np.save(filename, distance_matrix)\n",
    "    print(\"Distance matrix computation complete and saved to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec72477",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10  # Or any other number\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "clusters = kmeans.fit_predict(distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209190cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_words = pd.DataFrame({\n",
    "    'word': unique_words,\n",
    "    'cluster': clusters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f92038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
